{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.各種ライブラリ導入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named util.functions",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-86e36e593591>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#表示用に使用しています。\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mchainer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfunctions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named util.functions"
     ]
    }
   ],
   "source": [
    "#表示用に使用しています。\n",
    "from util.functions import trace\n",
    "import numpy as np\n",
    "\n",
    "from chainer import functions, optimizers\n",
    "\n",
    "#cpu計算とgpu計算で使い分けるラッパー\n",
    "from util.chainer_cpu_wrapper import wrapper\n",
    "\n",
    "from EncoderDecoderModel import EncoderDecoderModel\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#-------------Explain7 in the Qiita-------------\n",
    "n_epochs    = 30\n",
    "n_units     = 625\n",
    "batchsize   = 100\n",
    "#学習に使用する文字列の長さ\n",
    "bprop_len   = 10\n",
    "#勾配法で使用する敷居値\n",
    "grad_clip   = 0.5\n",
    "#学習データの格納場所\n",
    "data_dir = \"data_hands_on\"\n",
    "#モデルの出力場所：checkpoint_dir\n",
    "checkpoint_dir = \"cv\"\n",
    "#-------------Explain7 in the Qiita-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def source_to_words(source):\n",
    "    line = source.replace(\"¥n\", \" \").replace(\"¥t\", \" \")\n",
    "    for spacer in [\"(\", \")\", \"{\", \"}\", \"[\", \"]\", \",\", \";\", \":\", \"++\", \"!\", \"$\", '\"', \"'\"]:\n",
    "        line = line.replace(spacer, \" \" + spacer + \" \")\n",
    "    \n",
    "    words = [w.strip() for w in line.split()]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    vocab = {}\n",
    "    print ('%s/angular.js'% data_dir)\n",
    "    source = open('%s/angular_full_remake.js' % data_dir, 'r').read()\n",
    "    words = source_to_words(source)\n",
    "    freq = {}\n",
    "    dataset = np.ndarray((len(words),), dtype=np.int32)\n",
    "    for i, word in enumerate(words):\n",
    "        if word not in vocab:\n",
    "            vocab[word] = len(vocab)\n",
    "            freq[word] = 0\n",
    "        dataset[i] = vocab[word]\n",
    "        freq[word] += 1\n",
    "\n",
    "    print('corpus length:', len(words))\n",
    "    print('vocab size:', len(vocab))\n",
    "    return dataset, words, vocab, freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_hands_on/angular.js\n",
      "('corpus length:', 812928)\n",
      "('vocab size:', 6411)\n",
      "frequent words\n",
      "[(')', 71416), ('(', 71416), (';', 50808), (\"'\", 43648), (',', 43528), ('}', 32528), ('{', 32456), ('=', 27584), ('$', 27024), ('\"', 21000), (':', 16448), ('function', 12808), (']', 10616), ('[', 10600), ('var', 10160), ('if', 9808), ('return', 8192), ('!', 5424), ('value', 5296), ('element', 4288), ('0', 4216), ('+', 3888), ('>', 3736), ('scope', 3216), ('name', 3176), ('&&', 3056), ('||', 3024), ('?', 2928), ('i', 2704), ('===', 2544), ('key', 2360), ('else', 2344), ('1', 2256), ('true', 2192), ('expect', 1984), ('name=', 1912), ('==', 1848), ('this.', 1832), ('false', 1544), ('</file>', 1440), ('null', 1440), ('<file', 1440), ('ctrl.', 1280), ('locals', 1040), ('for', 1024), ('/', 1000), ('type=', 992), ('in', 984), ('forEach', 960), ('++', 952)]\n",
      "rarely words\n",
      "[('node.parentNode.removeChild', 8), ('user.name=', 8), ('codeName', 8), ('Int32', 8), ('inject.push', 8), ('locale.pluralCat', 8), ('<pre>form', 8), ('textElement', 8), ('logMsg', 8), ('currentOptionElement', 8), ('scope.checkboxModel', 8), ('http.pendingRequests', 8), ('node.ng339', 8), ('result.data', 8), ('.firstChild', 8), ('requireBase', 8), ('CookieReader.', 8), ('second', 8), ('here', 8), ('myForm.myWidget.', 8), ('ngRequired', 8), ('options.updateOn.replace', 8), ('parseArguments', 8), ('.has-error', 8), ('.animate-hide', 8), ('parsedUrl.port', 8), ('fraction.length', 8), ('99', 8), ('export', 8), ('91', 8), ('BinaryExpression', 8), ('95', 8), ('data-bind', 8), ('delayedNodeLinkFn', 8), ('getWatchables', 8), ('fn.name', 8), ('want', 8), ('invokeQueue.push', 8), ('predicates.push', 8), ('k.split', 8), ('assing', 8), ('></select>', 8), ('found...</strong>', 8), ('fix', 8), ('this.readNumber', 8), ('scope.template', 8), ('animateProvider.classNameFilter', 8), ('onNewScopeDestroyed.length', 8), ('its', 8), ('properties.push', 8)]\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.mkdir(checkpoint_dir)\n",
    "\n",
    "train_data, words, vocab, freq = load_data()\n",
    "\n",
    "for f in [\"frequent\", \"rarely\"]:\n",
    "    print(\"{0} words\".format(f))\n",
    "    print(sorted(freq.items(), key=lambda i: i[1], reverse=True if f == \"frequent\" else False)[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CharRNN(FunctionSet):\n",
    "\n",
    "    \"\"\"\n",
    "    ニューラルネットワークを定義している部分です。\n",
    "    上から順に入力された辞書ベクトル空間を隠れ層のユニット数に変換し、次に隠れ層の入\n",
    "    力と隠れ層を設定しています。\n",
    "    同様の処理を2層にも行い、出力層では語彙数に修正して出力しています。\n",
    "    なお最初に設定するパラメータは-0.08から0.08の間でランダムに設定しています。\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_vocab, n_units):\n",
    "        super(CharRNN, self).__init__(\n",
    "            embed = F.EmbedID(n_vocab, n_units),\n",
    "            l1_x = F.Linear(n_units, 4*n_units),\n",
    "            l1_h = F.Linear(n_units, 4*n_units),\n",
    "            l2_x = F.Linear(n_units, 4*n_units),\n",
    "            l2_h = F.Linear(n_units, 4*n_units),\n",
    "            l3   = F.Linear(n_units, n_vocab),\n",
    "        )\n",
    "        for param in self.parameters:\n",
    "            param[:] = np.random.uniform(-0.08, 0.08, param.shape)\n",
    "\n",
    "    \"\"\"\n",
    "    順伝搬の記述です。\n",
    "    順伝搬の入力をVariableで定義し、入力と答えを渡しています。\n",
    "    入力層を先ほど定義したembedを用います。\n",
    "    隠れ層の入力には、先ほど定義したl1_xを用いて、引数にdropout、隠れ層の状態を渡して\n",
    "    います。\n",
    "    lstmに隠れ層第1層の状態とh1_inを渡します。\n",
    "    2層目も同様に記述し、出力層は状態を渡さずに定義します。\n",
    "    次回以降の入力に使用するため各状態は保持しています。\n",
    "    出力されたラベルと答えのラベル比較し、損失を返すのと状態を返しています。\n",
    "    \"\"\"\n",
    "\n",
    "    def forward_one_step(self, x_data, y_data, state, train=True, dropout_ratio=0.5):\n",
    "        x = Variable(x_data, volatile=not train)\n",
    "        t = Variable(y_data, volatile=not train)\n",
    "\n",
    "        h0      = self.embed(x)\n",
    "        h1_in   = self.l1_x(F.dropout(h0, ratio=dropout_ratio, train=train)) + self.l1_h(state['h1'])\n",
    "        c1, h1  = F.lstm(state['c1'], h1_in)\n",
    "        h2_in   = self.l2_x(F.dropout(h1, ratio=dropout_ratio, train=train)) + self.l2_h(state['h2'])\n",
    "        c2, h2  = F.lstm(state['c2'], h2_in)\n",
    "        y       = self.l3(F.dropout(h2, ratio=dropout_ratio, train=train))\n",
    "        state   = {'c1': c1, 'h1': h1, 'c2': c2, 'h2': h2}\n",
    "\n",
    "        return state, F.softmax_cross_entropy(y, t)\n",
    "\n",
    "    \"\"\"\n",
    "    dropoutの記述を外して予測用のメソッドとして記述しています。\n",
    "    dropoutにはtrainという引数が存在し、trainの引数をfalseにしておくと動作しない\n",
    "    ので、予測の時は渡す引数を変えて学習と予測を変えても良いですが、今回は明示的に分る\n",
    "    ように分けて記述しました。\n",
    "    \"\"\"\n",
    "\n",
    "    def predict(self, x_data, state):\n",
    "        x = Variable(x_data, volatile=True)\n",
    "\n",
    "        h0      = self.embed(x)\n",
    "        h1_in   = self.l1_x(h0) + self.l1_h(state['h1'])\n",
    "        c1, h1  = F.lstm(state['c1'], h1_in)\n",
    "        h2_in   = self.l2_x(h1) + self.l2_h(state['h2'])\n",
    "        c2, h2  = F.lstm(state['c2'], h2_in)\n",
    "        y       = self.l3(h2)\n",
    "        state   = {'c1': c1, 'h1': h1, 'c2': c2, 'h2': h2}\n",
    "\n",
    "        return state, F.softmax(y)\n",
    "\n",
    "\"\"\"\n",
    "状態の初期化です。\n",
    "\"\"\"\n",
    "def make_initial_state(n_units, batchsize=100, train=True):\n",
    "    return {name: Variable(np.zeros((batchsize, n_units), dtype=np.float32),\n",
    "            volatile=not train)\n",
    "            for name in ('c1', 'h1', 'c2', 'h2')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prepare RNNLM model\n",
    "model = CharRNN(len(vocab), n_units)\n",
    "\n",
    "optimizer = optimizers.RMSprop(lr=2e-3, alpha=0.95, eps=1e-8)\n",
    "optimizer.setup(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "学習データのサイズを取得\n",
    "ジャンプの幅を設定（順次学習しない）\n",
    "パープレキシティを0で初期化\n",
    "最初の時間情報を取得\n",
    "初期状態を現在の状態に付与\n",
    "状態の初期化\n",
    "損失を0で初期化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "whole_len    = train_data.shape[0]\n",
    "jump         = whole_len // batchsize\n",
    "epoch        = 0\n",
    "start_at     = time.time()\n",
    "cur_at       = start_at\n",
    "state        = make_initial_state(n_units, batchsize=batchsize)\n",
    "accum_loss   = Variable(np.zeros((), dtype=np.float32))\n",
    "cur_log_perp = np.zeros(())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
